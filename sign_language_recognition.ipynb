{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDNE_QCO7YI2"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtnmxx_S7hFL",
    "outputId": "8b7d898c-c0e1-4737-fffc-39e931c3832c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRID4Xsw7wN3"
   },
   "outputs": [],
   "source": [
    "!unzip 'drive/MyDrive/emg_imu_data.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1nIXwYOH9q7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       ___                _            _            _          \n",
      "      |__ \\              | |          | |          | |         \n",
      "  ___    ) | _ __    ___ | |_  ______ | |__    ___ | |_   __ _ \n",
      " / __|  / / | '_ \\  / _ \\| __||______|| '_ \\  / _ \\| __| / _` |\n",
      "| (__  / /_ | | | ||  __/| |_         | |_) ||  __/| |_ | (_| |\n",
      " \\___||____||_| |_| \\___| \\__|        |_.__/  \\___| \\__| \\__,_|\n",
      "                                                               \n",
      "         \n",
      "\n",
      "If you have any problems while preparing the data, you can submit an issue in this repository: https://openi.pcl.ac.cn/OpenIOSSG/c2net-pypi\n",
      "        \n",
      "Detected .code_cache_file already exists, code has been prepared!\n",
      "Start preparing the dataset emg_data ...\n",
      "✅ Completed preparing the dataset emg_data\n",
      "Start preparing the dataset imu_data ...\n",
      "✅ Completed preparing the dataset imu_data\n",
      "please set c2net_context.output_path as the output location\n"
     ]
    }
   ],
   "source": [
    "# 导入包\n",
    "from c2net.context import prepare, upload_output\n",
    "# 初始化导入数据集和预训练模型到容器内\n",
    "c2net_context = prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ienjhsvz9uJP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetPath = c2net_context.dataset_path\n",
    "datasetPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6iJH0eq9zVm"
   },
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tt-d_NYo91hx"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "!pip install scikit-learn -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENWVAUDVJtVY"
   },
   "source": [
    "## Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E6burzCXIyuA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7dVbxW2LASN"
   },
   "source": [
    "# Data\n",
    "\n",
    "## Dataset\n",
    "- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n",
    "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n",
    "- We randomly select 600 speakers from Voxceleb2.\n",
    "- Then preprocess the raw waveforms into mel-spectrograms.\n",
    "\n",
    "- Args:\n",
    "  - data_dir: The path to the data directory.\n",
    "  - metadata_path: The path to the metadata.\n",
    "  - segment_len: The length of audio segment for training.\n",
    "- The architecture of data directory \\\\\n",
    "  - data directory \\\\\n",
    "  |---- metadata.json \\\\\n",
    "  |---- testdata.json \\\\\n",
    "  |---- mapping.json \\\\\n",
    "  |---- uttr-{random string}.pt \\\\\n",
    "\n",
    "- The information in metadata\n",
    "  - \"n_mels\": The dimention of mel-spectrogram.\n",
    "  - \"speakers\": A dictionary.\n",
    "    - Key: speaker ids.\n",
    "    - value: \"feature_path\" and \"mel_len\"\n",
    "\n",
    "\n",
    "For efficiency, we segment the mel-spectrograms into segments in the traing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8ozJ3rEh6xiR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, directory, seq_length=790, scaler=None):\n",
    "        self.directory = directory\n",
    "        self.seq_length = seq_length\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.scaler = scaler  # 将预先计算好的Scaler传入\n",
    "\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith(\"_emg.txt\"):\n",
    "                filepath = os.path.join(directory, f)\n",
    "                if os.path.getsize(filepath) > 0:\n",
    "                    self.files.append(filepath)\n",
    "                    self.labels.append(f.split('_')[0])\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "        self.num_classes=len(np.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.files[idx]\n",
    "        emg_signals = np.loadtxt(filepath)\n",
    "        if emg_signals.shape[0] < self.seq_length:\n",
    "            pad = np.zeros((self.seq_length - emg_signals.shape[0], emg_signals.shape[1]))\n",
    "            emg_signals = np.vstack([emg_signals, pad])\n",
    "        elif emg_signals.shape[0] > self.seq_length:\n",
    "            emg_signals = emg_signals[:self.seq_length, :]\n",
    "\n",
    "        if self.scaler:\n",
    "            emg_signals = self.scaler.transform(emg_signals)  # 使用预先拟合的Scaler进行转换\n",
    "\n",
    "        emg_signals = torch.from_numpy(emg_signals).float()\n",
    "        return emg_signals, self.labels[idx]\n",
    "\n",
    "    def get_num_classes(self):\n",
    "\t\t    return self.num_classes\n",
    "\n",
    "\n",
    "\n",
    "# # Assuming 'path_to_your_directory' is the path to your data\n",
    "# dataset = EMGDataset('path_to_your_directory')\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, directory, seq_length=790, scaler=None):\n",
    "        self.directory = directory\n",
    "        self.seq_length = seq_length\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.scaler = scaler  # Optionally use a pre-fitted scaler\n",
    "\n",
    "        # Load files and labels based on the file naming convention\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith(\"_imu.txt\"):  # Ensure to load only IMU files\n",
    "                filepath = os.path.join(directory, f)\n",
    "                if os.path.getsize(filepath) > 0:  # Check if file is not empty\n",
    "                    self.files.append(filepath)\n",
    "                    label = f.split('_')[0]  # Assuming label is before the first underscore\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "        self.num_classes = len(np.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.files[idx]\n",
    "        imu_data = np.loadtxt(filepath)\n",
    "        \n",
    "        # Handle sequence length discrepancies\n",
    "        if imu_data.shape[0] < self.seq_length:\n",
    "            pad = np.zeros((self.seq_length - imu_data.shape[0], imu_data.shape[1]))\n",
    "            imu_data = np.vstack([imu_data, pad])\n",
    "        elif imu_data.shape[0] > self.seq_length:\n",
    "            imu_data = imu_data[:self.seq_length, :]\n",
    "        \n",
    "        # Apply scaling if a scaler is provided\n",
    "        if self.scaler:\n",
    "            imu_data = self.scaler.transform(imu_data)  # Transform data using the pre-fitted scaler\n",
    "\n",
    "        imu_data = torch.from_numpy(imu_data).float()\n",
    "        return imu_data, self.labels[idx]\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return self.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, emg_directory, imu_directory, seq_length=790, scaler=None):\n",
    "        self.seq_length = seq_length\n",
    "        self.scaler = scaler  # Optionally use a pre-fitted scaler\n",
    "\n",
    "        # Load files and labels from both directories\n",
    "        self.emg_files, self.imu_files, self.labels = self.load_files(emg_directory, imu_directory)\n",
    "\n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "    def load_files(self, emg_directory, imu_directory):\n",
    "        emg_files = []\n",
    "        imu_files = []\n",
    "        labels = []\n",
    "        \n",
    "        # Assuming same filenames for corresponding EMG and IMU files except extensions\n",
    "        for f in os.listdir(emg_directory):\n",
    "            if f.endswith(\"_emg.txt\"):\n",
    "                emg_filepath = os.path.join(emg_directory, f)\n",
    "                imu_filepath = os.path.join(imu_directory, f.replace(\"_emg.txt\", \"_imu.txt\"))\n",
    "                \n",
    "                if os.path.exists(imu_filepath) and os.path.getsize(emg_filepath) > 0 and os.path.getsize(imu_filepath) > 0:\n",
    "                    emg_files.append(emg_filepath)\n",
    "                    imu_files.append(imu_filepath)\n",
    "                    labels.append(f.split('_')[0])\n",
    "                    \n",
    "        return emg_files, imu_files, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emg_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emg_filepath = self.emg_files[idx]\n",
    "        imu_filepath = self.imu_files[idx]\n",
    "        \n",
    "        # Load data\n",
    "        emg_data = np.loadtxt(emg_filepath)\n",
    "        imu_data = np.loadtxt(imu_filepath)\n",
    "        \n",
    "        # Handle sequence length discrepancies for both data types\n",
    "        if emg_data.shape[0] < self.seq_length:\n",
    "            emg_data = np.vstack([emg_data, np.zeros((self.seq_length - emg_data.shape[0], emg_data.shape[1]))])\n",
    "        else:\n",
    "            emg_data = emg_data[:self.seq_length, :]\n",
    "        \n",
    "        if imu_data.shape[0] < self.seq_length:\n",
    "            imu_data = np.vstack([imu_data, np.zeros((self.seq_length - imu_data.shape[0], imu_data.shape[1]))])\n",
    "        else:\n",
    "            imu_data = imu_data[:self.seq_length, :]\n",
    "        \n",
    "        # Concatenate EMG and IMU data along feature axis\n",
    "        fused_data = np.concatenate([emg_data, imu_data], axis=1)\n",
    "        \n",
    "        if self.scaler:\n",
    "            fused_data = self.scaler.transform(fused_data)  # Transform data using the pre-fitted scaler\n",
    "        \n",
    "        fused_data = torch.from_numpy(fused_data).float()\n",
    "        return fused_data, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyjde_c2KuO5"
   },
   "source": [
    "## 计算sacler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM2uk0RLKtgO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def incremental_mean_std(directory, seq_length=790):\n",
    "    mean = np.zeros((seq_length, 8))  # 假设每个样本有8个特征\n",
    "    M2 = np.zeros((seq_length, 8))\n",
    "    n = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_emg.txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            if os.path.getsize(filepath) > 0:\n",
    "                data = np.loadtxt(filepath)\n",
    "                if data.size == 0:  # 检查数据是否为空\n",
    "                    continue\n",
    "                if data.shape[0] < seq_length:\n",
    "                    # 填充不足的数据\n",
    "                    pad = np.zeros((seq_length - data.shape[0], data.shape[1]))\n",
    "                    data = np.vstack([data, pad])\n",
    "                elif data.shape[0] > seq_length:\n",
    "                    # 截断超出的数据\n",
    "                    data = data[:seq_length, :]\n",
    "                n += 1\n",
    "                delta = data - mean\n",
    "                mean += delta / n\n",
    "                M2 += delta * (data - mean)\n",
    "\n",
    "    std = np.sqrt(M2 / n) if n > 1 else np.sqrt(M2)\n",
    "    return mean, std\n",
    "\n",
    "# directory = 'emg_data'\n",
    "# mean, std = incremental_mean_std(directory)\n",
    "\n",
    "# 用得到的 mean 和 std 来创建一个 StandardScaler-like 的类\n",
    "class CustomScaler:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7GDv3MNK4Ou"
   },
   "outputs": [],
   "source": [
    "directory = 'emg_data'\n",
    "mean, std = incremental_mean_std(directory)\n",
    "scaler = CustomScaler(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EOAlzmBqPDhh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 从文件加载scaler对象\n",
    "# filepath = 'drive/MyDrive/scaler.pkl'\n",
    "filepath = 'scaler.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "    scaler = loaded_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_KOJtnhPHck"
   },
   "outputs": [],
   "source": [
    "# 使用加载的scaler来转换数据\n",
    "# transformed_data = loaded_scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbxB6Re5K-AH"
   },
   "outputs": [],
   "source": [
    "dataset = EMGDataset(directory=directory, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYx62gBv96if"
   },
   "outputs": [],
   "source": [
    "directory='emg_data'\n",
    "# scaler = compute_statistics(directory)\n",
    "\n",
    "dataset = EMGDataset(directory=directory, scaler=scaler)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPNw4tAcbG4W"
   },
   "source": [
    "## 确定seq_length\n",
    "确定seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r06nf5k2KA_x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "lengths0 = []\n",
    "lengths1 = []\n",
    "def analyze_emg_lengths(directory):\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_emg.txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                emg_signals = np.loadtxt(filepath)\n",
    "                if emg_signals.shape[0]!=0:\n",
    "                  lengths0.append(emg_signals.shape[0])\n",
    "                  lengths1.append(emg_signals.shape[1])\n",
    "\n",
    "            except:\n",
    "                # Handling empty or corrupted files\n",
    "                print(f\"Could not load data from {filename}\")\n",
    "    return lengths0, lengths1\n",
    "\n",
    "# Assuming 'path_to_your_directory' is the path to your data\n",
    "# directory = 'emg_data'\n",
    "# lengths = analyze_emg_lengths(directory)\n",
    "\n",
    "# # Calculate statistics\n",
    "# if lengths0:\n",
    "#     min_length0 = np.min(lengths0)\n",
    "#     max_length0 = np.max(lengths0)\n",
    "#     avg_length0 = np.mean(lengths0)\n",
    "#     median_length0 = np.median(lengths0)\n",
    "\n",
    "#     min_length1 = np.min(lengths1)\n",
    "#     max_length1 = np.max(lengths1)\n",
    "#     avg_length1 = np.mean(lengths1)\n",
    "#     median_length1 = np.median(lengths1)\n",
    "\n",
    "#     print(f\"Minimum length: {min_length0}, {min_length1}\")\n",
    "#     print(f\"Maximum length: {max_length0}， {max_length1}\")\n",
    "#     print(f\"Average length: {avg_length0:.2f}, {avg_length1:.2f}\")\n",
    "#     print(f\"Median length: {median_length0}, {median_length1}\")\n",
    "# else:\n",
    "#     print(\"No data available to analyze.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "668hverTMlGN"
   },
   "source": [
    "## Dataloader\n",
    "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
    "- Create dataloader to iterate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO7Dmmsm8PYD"
   },
   "outputs": [],
   "source": [
    "# scaler=scaler\n",
    "scaler=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QrOnyMOidsem"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def emg_collate_batch(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    return torch.stack(data), torch.tensor(labels)\n",
    "\n",
    "def get_emg_dataloader(data_dir, batch_size, n_workers):\n",
    "    dataset = EMGDataset(directory=data_dir, scaler=scaler)\n",
    "    num_classes = dataset.get_num_classes()\n",
    "    # 分割数据集为训练集和验证集\n",
    "    train_len = int(0.9 * len(dataset))\n",
    "    lengths = [train_len, len(dataset) - train_len]\n",
    "    train_set, valid_set = random_split(dataset, lengths)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=emg_collate_batch,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=n_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        collate_fn=emg_collate_batch,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FOSZYxrMqhc"
   },
   "source": [
    "# Model\n",
    "- TransformerEncoderLayer:\n",
    "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "  - Parameters:\n",
    "    - d_model: the number of expected features of the input (required).\n",
    "\n",
    "    - nhead: the number of heads of the multiheadattention models (required).\n",
    "\n",
    "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "\n",
    "    - dropout: the dropout value (default=0.1).\n",
    "\n",
    "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "\n",
    "- TransformerEncoder:\n",
    "  - TransformerEncoder is a stack of N transformer encoder layers\n",
    "  - Parameters:\n",
    "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "\n",
    "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "\n",
    "    - norm: the layer normalization component (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EmNGNr796xiS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_dim=8, d_model=224, ff_dim=256, num_heads=2, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Project the dimension of features from that of input into an enhanced feature space\n",
    "        self.prenet = nn.Linear(input_dim, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, dim_feedforward=d_model*2, nhead=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prenet(x)  # Apply prenet\n",
    "        x = self.encoder(x)  # Transformer encoder\n",
    "        x = x.transpose(1, 2)  # Change (batch, seq_len, features) to (batch, features, seq_len)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Assuming 8 features per timestep and the sequence length is the same for all samples\n",
    "# model = TransformerModel(input_dim=8, num_heads=2, ff_dim=256, num_classes=len(np.unique(dataset.labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7yX8JinM5Ly"
   },
   "source": [
    "# Learning rate schedule\n",
    "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
    "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
    "- The warmup schedule\n",
    "  - Set learning rate to 0 in the beginning.\n",
    "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ykt0N1nVJJi2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "\toptimizer: Optimizer,\n",
    "\tnum_warmup_steps: int,\n",
    "\tnum_training_steps: int,\n",
    "\tnum_cycles: float = 0.5,\n",
    "\tlast_epoch: int = -1,\n",
    "):\n",
    "\t\"\"\"\n",
    "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
    "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
    "\tinitial lr set in the optimizer.\n",
    "\n",
    "\tArgs:\n",
    "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
    "\t\tThe optimizer for which to schedule the learning rate.\n",
    "\t\tnum_warmup_steps (:obj:`int`):\n",
    "\t\tThe number of steps for the warmup phase.\n",
    "\t\tnum_training_steps (:obj:`int`):\n",
    "\t\tThe total number of training steps.\n",
    "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
    "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
    "\t\tfollowing a half-cosine).\n",
    "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
    "\t\tThe index of the last epoch when resuming training.\n",
    "\n",
    "\tReturn:\n",
    "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "\t\"\"\"\n",
    "\tdef lr_lambda(current_step):\n",
    "\t\t# Warmup\n",
    "\t\tif current_step < num_warmup_steps:\n",
    "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
    "\t\t# decadence\n",
    "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
    "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
    "\t\t)\n",
    "\t\treturn max(\n",
    "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "\t\t)\n",
    "\n",
    "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LN2XkteM_uH"
   },
   "source": [
    "# Model Function\n",
    "- Model forward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d-AWw5v5hYpB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def model_fn(batch, model, criterion, device):\n",
    "    \"\"\"Forward a batch through the model.\"\"\"\n",
    "\n",
    "    # 解包批数据\n",
    "    data, labels = batch\n",
    "    # 将数据和标签转移到指定设备（例如 GPU）\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # 通过模型进行前向传播得到输出\n",
    "    outs = model(data)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(outs, labels)\n",
    "\n",
    "    # 计算预测的类别（最高得分的类别）\n",
    "    preds = outs.argmax(1)\n",
    "    # 计算准确率\n",
    "    accuracy = torch.mean((preds == labels).float())\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwM_xyOtNCI2"
   },
   "source": [
    "# Validate\n",
    "- Calculate accuracy of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hZOaHCCblegt"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def valid(dataloader, model, criterion, device):\n",
    "    \"\"\"Validate on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\"sample\")\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy.item()\n",
    "\n",
    "        pbar.update(dataloader.batch_size)\n",
    "        pbar.set_postfix(\n",
    "            loss=f\"{running_loss / (i+1):.2f}\",\n",
    "            accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
    "        )\n",
    "\n",
    "    pbar.close()\n",
    "    model.train()\n",
    "\n",
    "    return running_accuracy / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ne9G-eNEdG"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "H4V6JgNMlrzR",
    "outputId": "5731ae50-9e9e-4740-985f-92f31d4d4b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 500/500 [03:28<00:00,  2.40 step/s, accuracy=0.00, loss=5.89, step=500]\n",
      "Valid: 100% 7616/7622 [00:16<00:00, 469.49sample/s, accuracy=0.01, loss=5.97]\n",
      "Train: 100% 500/500 [03:18<00:00,  2.52 step/s, accuracy=0.03, loss=6.11, step=1000]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 566.67sample/s, accuracy=0.01, loss=6.09]\n",
      "Train: 100% 500/500 [03:16<00:00,  2.55 step/s, accuracy=0.00, loss=5.74, step=1500]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 561.08sample/s, accuracy=0.01, loss=6.61]\n",
      "Train: 100% 500/500 [03:14<00:00,  2.57 step/s, accuracy=0.00, loss=6.02, step=2000]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 561.59sample/s, accuracy=0.00, loss=6.89]\n",
      "Train: 100% 500/500 [03:13<00:00,  2.59 step/s, accuracy=0.00, loss=6.13, step=2500]\n",
      "Valid: 100% 7616/7622 [00:14<00:00, 517.34sample/s, accuracy=0.00, loss=7.01]\n",
      "Train:   0% 0/500 [00:00<?, ? step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500, best model saved. (accuracy=0.0100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 500/500 [03:12<00:00,  2.60 step/s, accuracy=0.03, loss=5.91, step=3000]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 562.61sample/s, accuracy=0.00, loss=7.33]\n",
      "Train: 100% 500/500 [03:11<00:00,  2.61 step/s, accuracy=0.00, loss=6.32, step=3500]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 565.02sample/s, accuracy=0.01, loss=6.08]\n",
      "Train: 100% 500/500 [03:11<00:00,  2.61 step/s, accuracy=0.00, loss=6.25, step=4000]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 563.38sample/s, accuracy=0.00, loss=7.58]\n",
      "Train: 100% 500/500 [03:11<00:00,  2.61 step/s, accuracy=0.03, loss=5.43, step=4500]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 559.72sample/s, accuracy=0.01, loss=6.63]\n",
      "Train: 100% 500/500 [03:10<00:00,  2.63 step/s, accuracy=0.06, loss=5.50, step=5000]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 564.61sample/s, accuracy=0.01, loss=6.76]\n",
      "Train:   0% 0/500 [00:00<?, ? step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5000, best model saved. (accuracy=0.0100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100% 500/500 [03:11<00:00,  2.61 step/s, accuracy=0.00, loss=5.49, step=5500]\n",
      "Valid: 100% 7616/7622 [00:13<00:00, 561.07sample/s, accuracy=0.01, loss=6.13]\n",
      "Train:   5% 27/500 [00:10<02:59,  2.63 step/s, accuracy=0.03, loss=5.95, step=5527]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from get_emg_dataloader import get_emg_dataloader\n",
    "# from your_model_file import TransformerModel, model_fn, valid\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"arguments\"\"\"\n",
    "    config = {\n",
    "        # \"data_dir\": \"./emg_data\",\n",
    "        \"data_dir\": \"/tmp/dataset/emg_data/emg_data\",\n",
    "        \"save_path\": \"model.ckpt\",\n",
    "        \"batch_size\": 32,\n",
    "        \"n_workers\": 2,\n",
    "        \"valid_steps\": 500,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"save_steps\": 2500,\n",
    "        \"total_steps\": 7500,\n",
    "        \"pretrained_path\": None,  # 可以设置为预先训练好的模型路径\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def main(\n",
    "    data_dir,\n",
    "    save_path,\n",
    "    batch_size,\n",
    "    n_workers,\n",
    "    valid_steps,\n",
    "    warmup_steps,\n",
    "    total_steps,\n",
    "    save_steps,\n",
    "    pretrained_path=None,\n",
    "):\n",
    "    \"\"\"Main function.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "    train_loader, valid_loader, num_classes = get_emg_dataloader(data_dir, batch_size, n_workers)\n",
    "    print(f\"[Info]: Finish loading data!\", flush=True)\n",
    "\n",
    "    model = TransformerModel(num_classes=num_classes).to(device)\n",
    "    if pretrained_path:\n",
    "        model.load_state_dict(torch.load(pretrained_path, map_location=device))\n",
    "        print(\"[Info]: Pretrained model loaded!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "\n",
    "    print(f\"[Info]: Finish creating model!\", flush=True)\n",
    "\n",
    "    best_accuracy = -1.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            batch = next(iter(train_loader))\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            batch = next(train_iterator)\n",
    "\n",
    "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_postfix(\n",
    "            loss=f\"{loss.item():.2f}\",\n",
    "            accuracy=f\"{accuracy:.2f}\",\n",
    "            step=step + 1,\n",
    "        )\n",
    "\n",
    "        if (step + 1) % valid_steps == 0:\n",
    "            pbar.close()\n",
    "            valid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "\n",
    "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "            torch.save(best_state_dict, save_path)\n",
    "            print(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(**parse_args())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLatBYAhNNMx"
   },
   "source": [
    "# Inference\n",
    "\n",
    "## Dataset of inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efS4pCmAJXJH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "\tdef __init__(self, data_dir):\n",
    "\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n",
    "\t\tmetadata = json.load(testdata_path.open())\n",
    "\t\tself.data_dir = data_dir\n",
    "\t\tself.data = metadata[\"utterances\"]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tutterance = self.data[index]\n",
    "\t\tfeat_path = utterance[\"feature_path\"]\n",
    "\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "\t\treturn feat_path, mel\n",
    "\n",
    "\n",
    "def inference_collate_batch(batch):\n",
    "\t\"\"\"Collate a batch of data.\"\"\"\n",
    "\tfeat_paths, mels = zip(*batch)\n",
    "\n",
    "\treturn feat_paths, torch.stack(mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl0WnYwxNK_S"
   },
   "source": [
    "## Main funcrion of Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "f55456f66b2f4194bf09e5bb2d0aa056",
      "1ec97c36e27e4c4e9e363e5ec9c18d91",
      "dfd5ff417c64471b89a92e2507b5862e",
      "c3606c4a79484900b1908e5adc8e03e8",
      "bece48b02f684ddaa1e879adb7473594",
      "6b7aea63809148d2bd14132d841030e7",
      "003e9920d1614b658084ac73c0c7a433",
      "d4efe5163fb346e7ac692657aee81c1f",
      "3941431284af4546a75d3fff846a1d2d",
      "4c884a89a2e648cda64bdbbd9a69379c",
      "59856358c1954fbc9eae3b77b63e82fc"
     ]
    },
    "id": "i8SAbuXEJb2A",
    "outputId": "464f9a64-efc3-4d79-9845-36bb881f730f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55456f66b2f4194bf09e5bb2d0aa056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def parse_args():\n",
    "\t\"\"\"arguments\"\"\"\n",
    "\tconfig = {\n",
    "\t\t\"data_dir\": \"./Dataset\",\n",
    "\t\t\"model_path\": \"./model.ckpt\",\n",
    "\t\t\"output_path\": \"./output.csv\",\n",
    "\t}\n",
    "\n",
    "\treturn config\n",
    "\n",
    "\n",
    "def main(\n",
    "\tdata_dir,\n",
    "\tmodel_path,\n",
    "\toutput_path,\n",
    "):\n",
    "\t\"\"\"Main function.\"\"\"\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tprint(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
    "\tmapping = json.load(mapping_path.open())\n",
    "\n",
    "\tdataset = InferenceDataset(data_dir)\n",
    "\tdataloader = DataLoader(\n",
    "\t\tdataset,\n",
    "\t\tbatch_size=1,\n",
    "\t\tshuffle=False,\n",
    "\t\tdrop_last=False,\n",
    "\t\tnum_workers=8,\n",
    "\t\tcollate_fn=inference_collate_batch,\n",
    "\t)\n",
    "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
    "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
    "\tmodel.load_state_dict(torch.load(model_path))\n",
    "\tmodel.eval()\n",
    "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "\tresults = [[\"Id\", \"Category\"]]\n",
    "\tfor feat_paths, mels in tqdm(dataloader):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tmels = mels.to(device)\n",
    "\t\t\touts = model(mels)\n",
    "\t\t\tpreds = outs.argmax(1).cpu().numpy()\n",
    "\t\t\tfor feat_path, pred in zip(feat_paths, preds):\n",
    "\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
    "\n",
    "\twith open(output_path, 'w', newline='') as csvfile:\n",
    "\t\twriter = csv.writer(csvfile)\n",
    "\t\twriter.writerows(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain(**parse_args())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003e9920d1614b658084ac73c0c7a433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ec97c36e27e4c4e9e363e5ec9c18d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b7aea63809148d2bd14132d841030e7",
      "placeholder": "​",
      "style": "IPY_MODEL_003e9920d1614b658084ac73c0c7a433",
      "value": "100%"
     }
    },
    "3941431284af4546a75d3fff846a1d2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c884a89a2e648cda64bdbbd9a69379c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59856358c1954fbc9eae3b77b63e82fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b7aea63809148d2bd14132d841030e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bece48b02f684ddaa1e879adb7473594": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3606c4a79484900b1908e5adc8e03e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c884a89a2e648cda64bdbbd9a69379c",
      "placeholder": "​",
      "style": "IPY_MODEL_59856358c1954fbc9eae3b77b63e82fc",
      "value": " 8000/8000 [00:29&lt;00:00, 201.09it/s]"
     }
    },
    "d4efe5163fb346e7ac692657aee81c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfd5ff417c64471b89a92e2507b5862e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4efe5163fb346e7ac692657aee81c1f",
      "max": 8000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3941431284af4546a75d3fff846a1d2d",
      "value": 8000
     }
    },
    "f55456f66b2f4194bf09e5bb2d0aa056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ec97c36e27e4c4e9e363e5ec9c18d91",
       "IPY_MODEL_dfd5ff417c64471b89a92e2507b5862e",
       "IPY_MODEL_c3606c4a79484900b1908e5adc8e03e8"
      ],
      "layout": "IPY_MODEL_bece48b02f684ddaa1e879adb7473594"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
