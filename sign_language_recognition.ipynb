{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDNE_QCO7YI2"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtnmxx_S7hFL",
    "outputId": "8b7d898c-c0e1-4737-fffc-39e931c3832c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRID4Xsw7wN3"
   },
   "outputs": [],
   "source": [
    "!unzip 'drive/MyDrive/emg_imu_data.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1nIXwYOH9q7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       ___                _            _            _          \n",
      "      |__ \\              | |          | |          | |         \n",
      "  ___    ) | _ __    ___ | |_  ______ | |__    ___ | |_   __ _ \n",
      " / __|  / / | '_ \\  / _ \\| __||______|| '_ \\  / _ \\| __| / _` |\n",
      "| (__  / /_ | | | ||  __/| |_         | |_) ||  __/| |_ | (_| |\n",
      " \\___||____||_| |_| \\___| \\__|        |_.__/  \\___| \\__| \\__,_|\n",
      "                                                               \n",
      "         \n",
      "\n",
      "If you have any problems while preparing the data, you can submit an issue in this repository: https://openi.pcl.ac.cn/OpenIOSSG/c2net-pypi\n",
      "        \n",
      "Detected .code_cache_file already exists, code has been prepared!\n",
      "Detected .dataset_cache_file already exists, dataset has been prepared!\n",
      "please set c2net_context.output_path as the output location\n"
     ]
    }
   ],
   "source": [
    "# 导入包\n",
    "from c2net.context import prepare, upload_output\n",
    "# 初始化导入数据集和预训练模型到容器内\n",
    "c2net_context = prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ienjhsvz9uJP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetPath = c2net_context.dataset_path\n",
    "datasetPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据集路径\n",
    "imu_data_path = c2net_context.dataset_path+\"/\"+\"imu_data\"\n",
    "emg_data_path = c2net_context.dataset_path+\"/\"+\"emg_data\"\n",
    "\n",
    "#输出结果必须保存在该目录\n",
    "you_should_save_here = c2net_context.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_data_path = c2net_context.dataset_path+\"/\"+\"imu_data\"+\"/\"+\"imu_data\"\n",
    "emg_data_path = c2net_context.dataset_path+\"/\"+\"emg_data\"+\"/\"+\"emg_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6iJH0eq9zVm"
   },
   "source": [
    "## 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tt-d_NYo91hx"
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "!pip install scikit-learn -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENWVAUDVJtVY"
   },
   "source": [
    "## Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "E6burzCXIyuA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# set_seed(87)\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7dVbxW2LASN"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class FusedDataset(Dataset):\n",
    "    def __init__(self, emg_directory, imu_directory, emg_seq_length=790, imu_seq_length=205):\n",
    "        self.emg_seq_length = emg_seq_length\n",
    "        self.imu_seq_length = imu_seq_length\n",
    "        self.emg_files = []\n",
    "        self.imu_files = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load EMG and IMU files\n",
    "        emg_files = {f.split('_')[0]: f for f in os.listdir(emg_directory) if f.endswith(\"_emg.txt\")}\n",
    "        imu_files = {f.split('_')[0]: f for f in os.listdir(imu_directory) if f.endswith(\"_imu.txt\")}\n",
    "\n",
    "        # Ensure only pairs with matching labels are added\n",
    "        for label in emg_files:\n",
    "            if label in imu_files:\n",
    "                emg_filepath = os.path.join(emg_directory, emg_files[label])\n",
    "                imu_filepath = os.path.join(imu_directory, imu_files[label])\n",
    "                if os.path.getsize(emg_filepath) > 0 and os.path.getsize(imu_filepath) > 0:\n",
    "                    self.emg_files.append(emg_filepath)\n",
    "                    self.imu_files.append(imu_filepath)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emg_path = self.emg_files[idx]\n",
    "        imu_path = self.imu_files[idx]\n",
    "        emg_signals = self.load_and_process_data(emg_path, self.emg_seq_length)\n",
    "        imu_signals = self.load_and_process_data(imu_path, self.imu_seq_length)\n",
    "        \n",
    "        return emg_signals, imu_signals, self.labels[idx]\n",
    "\n",
    "    def load_and_process_data(self, filepath, seq_length):\n",
    "        data = np.loadtxt(filepath)\n",
    "        if data.shape[0] < seq_length:\n",
    "            data = np.vstack([data, np.zeros((seq_length - data.shape[0], data.shape[1]))])\n",
    "        elif data.shape[0] > seq_length:\n",
    "            data = data[:seq_length, :]\n",
    "        return torch.from_numpy(data).float()\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return len(np.unique(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8ozJ3rEh6xiR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, directory, seq_length=790, scaler=None):\n",
    "        self.directory = directory\n",
    "        self.seq_length = seq_length\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.scaler = scaler  # 将预先计算好的Scaler传入\n",
    "\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith(\"_emg.txt\"):\n",
    "                filepath = os.path.join(directory, f)\n",
    "                if os.path.getsize(filepath) > 0:\n",
    "                    self.files.append(filepath)\n",
    "                    self.labels.append(f.split('_')[0])\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "        self.num_classes=len(np.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.files[idx]\n",
    "        emg_signals = np.loadtxt(filepath)\n",
    "        if emg_signals.shape[0] < self.seq_length:\n",
    "            pad = np.zeros((self.seq_length - emg_signals.shape[0], emg_signals.shape[1]))\n",
    "            emg_signals = np.vstack([emg_signals, pad])\n",
    "        elif emg_signals.shape[0] > self.seq_length:\n",
    "            emg_signals = emg_signals[:self.seq_length, :]\n",
    "\n",
    "        if self.scaler:\n",
    "            emg_signals = self.scaler.transform(emg_signals)  # 使用预先拟合的Scaler进行转换\n",
    "\n",
    "        emg_signals = torch.from_numpy(emg_signals).float()\n",
    "        return emg_signals, self.labels[idx]\n",
    "\n",
    "    def get_num_classes(self):\n",
    "\t\t    return self.num_classes\n",
    "\n",
    "\n",
    "\n",
    "# # Assuming 'path_to_your_directory' is the path to your data\n",
    "# dataset = EMGDataset('path_to_your_directory')\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, directory, seq_length=790, scaler=None):\n",
    "        self.directory = directory\n",
    "        self.seq_length = seq_length\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.scaler = scaler  # Optionally use a pre-fitted scaler\n",
    "\n",
    "        # Load files and labels based on the file naming convention\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith(\"_imu.txt\"):  # Ensure to load only IMU files\n",
    "                filepath = os.path.join(directory, f)\n",
    "                if os.path.getsize(filepath) > 0:  # Check if file is not empty\n",
    "                    self.files.append(filepath)\n",
    "                    label = f.split('_')[0]  # Assuming label is before the first underscore\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        # Encode labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "        self.num_classes = len(np.unique(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.files[idx]\n",
    "        imu_data = np.loadtxt(filepath)\n",
    "        \n",
    "        # Handle sequence length discrepancies\n",
    "        if imu_data.shape[0] < self.seq_length:\n",
    "            pad = np.zeros((self.seq_length - imu_data.shape[0], imu_data.shape[1]))\n",
    "            imu_data = np.vstack([imu_data, pad])\n",
    "        elif imu_data.shape[0] > self.seq_length:\n",
    "            imu_data = imu_data[:self.seq_length, :]\n",
    "        \n",
    "        # Apply scaling if a scaler is provided\n",
    "        if self.scaler:\n",
    "            imu_data = self.scaler.transform(imu_data)  # Transform data using the pre-fitted scaler\n",
    "\n",
    "        imu_data = torch.from_numpy(imu_data).float()\n",
    "        return imu_data, self.labels[idx]\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return self.num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyjde_c2KuO5"
   },
   "source": [
    "## 计算sacler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM2uk0RLKtgO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def incremental_mean_std(directory, seq_length=790):\n",
    "    mean = np.zeros((seq_length, 8))  # 假设每个样本有8个特征\n",
    "    M2 = np.zeros((seq_length, 8))\n",
    "    n = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_emg.txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            if os.path.getsize(filepath) > 0:\n",
    "                data = np.loadtxt(filepath)\n",
    "                if data.size == 0:  # 检查数据是否为空\n",
    "                    continue\n",
    "                if data.shape[0] < seq_length:\n",
    "                    # 填充不足的数据\n",
    "                    pad = np.zeros((seq_length - data.shape[0], data.shape[1]))\n",
    "                    data = np.vstack([data, pad])\n",
    "                elif data.shape[0] > seq_length:\n",
    "                    # 截断超出的数据\n",
    "                    data = data[:seq_length, :]\n",
    "                n += 1\n",
    "                delta = data - mean\n",
    "                mean += delta / n\n",
    "                M2 += delta * (data - mean)\n",
    "\n",
    "    std = np.sqrt(M2 / n) if n > 1 else np.sqrt(M2)\n",
    "    return mean, std\n",
    "\n",
    "# directory = 'emg_data'\n",
    "# mean, std = incremental_mean_std(directory)\n",
    "\n",
    "# 用得到的 mean 和 std 来创建一个 StandardScaler-like 的类\n",
    "class CustomScaler:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean) / self.std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7GDv3MNK4Ou"
   },
   "outputs": [],
   "source": [
    "directory = 'emg_data'\n",
    "mean, std = incremental_mean_std(directory)\n",
    "scaler = CustomScaler(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EOAlzmBqPDhh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 从文件加载scaler对象\n",
    "# filepath = 'drive/MyDrive/scaler.pkl'\n",
    "filepath = 'scaler.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "    scaler = loaded_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_KOJtnhPHck"
   },
   "outputs": [],
   "source": [
    "# 使用加载的scaler来转换数据\n",
    "# transformed_data = loaded_scaler.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbxB6Re5K-AH"
   },
   "outputs": [],
   "source": [
    "dataset = EMGDataset(directory=directory, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pYx62gBv96if"
   },
   "outputs": [],
   "source": [
    "# directory='emg_data'\n",
    "directory=emg_data_path\n",
    "# scaler = compute_statistics(directory)\n",
    "scaler = None\n",
    "dataset = EMGDataset(directory=directory, scaler=scaler)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_num_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPNw4tAcbG4W"
   },
   "source": [
    "## 确定seq_length\n",
    "确定seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r06nf5k2KA_x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "lengths0 = []\n",
    "lengths1 = []\n",
    "def analyze_emg_lengths(directory):\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_imu.txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                if os.path.getsize(filepath) > 0\n",
    "                  emg_signals = np.loadtxt(filepath)\n",
    "#                 if emg_signals.shape[0]!=0:\n",
    "                  lengths0.append(emg_signals.shape[0])\n",
    "                  lengths1.append(emg_signals.shape[1])\n",
    "\n",
    "            except:\n",
    "                # Handling empty or corrupted files\n",
    "                print(f\"Could not load data from {filename}\")\n",
    "    return lengths0, lengths1\n",
    "\n",
    "# Assuming 'path_to_your_directory' is the path to your data\n",
    "# directory = 'emg_data'\n",
    "directory = imu_data_path\n",
    "lengths = analyze_emg_lengths(directory)\n",
    "\n",
    "# Calculate statistics\n",
    "if lengths0:\n",
    "    min_length0 = np.min(lengths0)\n",
    "    max_length0 = np.max(lengths0)\n",
    "    avg_length0 = np.mean(lengths0)\n",
    "    median_length0 = np.median(lengths0)\n",
    "\n",
    "    min_length1 = np.min(lengths1)\n",
    "    max_length1 = np.max(lengths1)\n",
    "    avg_length1 = np.mean(lengths1)\n",
    "    median_length1 = np.median(lengths1)\n",
    "\n",
    "    print(f\"Minimum length: {min_length0}, {min_length1}\")\n",
    "    print(f\"Maximum length: {max_length0}， {max_length1}\")\n",
    "    print(f\"Average length: {avg_length0:.2f}, {avg_length1:.2f}\")\n",
    "    print(f\"Median length: {median_length0}, {median_length1}\")\n",
    "else:\n",
    "    print(\"No data available to analyze.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "668hverTMlGN"
   },
   "source": [
    "## Dataloader\n",
    "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
    "- Create dataloader to iterate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO7Dmmsm8PYD"
   },
   "outputs": [],
   "source": [
    "# scaler=scaler\n",
    "scaler=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from your_dataset_file import FusedDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def get_fused_dataloader(emg_dir, imu_dir, batch_size, n_workers):\n",
    "    dataset = FusedDataset(emg_directory=emg_dir, imu_directory=imu_dir)\n",
    "    num_classes = dataset.get_num_classes()\n",
    "    \n",
    "    # Splitting dataset into training and validation sets\n",
    "    train_len = int(0.9 * len(dataset))\n",
    "    lengths = [train_len, len(dataset) - train_len]\n",
    "    train_set, valid_set = random_split(dataset, lengths)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=n_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QrOnyMOidsem"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def emg_collate_batch(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    return torch.stack(data), torch.tensor(labels)\n",
    "\n",
    "def get_emg_dataloader(data_dir, batch_size, n_workers):\n",
    "    dataset = EMGDataset(directory=data_dir, scaler=scaler)\n",
    "    num_classes = dataset.get_num_classes()\n",
    "    # 分割数据集为训练集和验证集\n",
    "    train_len = int(0.9 * len(dataset))\n",
    "    lengths = [train_len, len(dataset) - train_len]\n",
    "    train_set, valid_set = random_split(dataset, lengths)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=n_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=emg_collate_batch,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=n_workers,\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "        collate_fn=emg_collate_batch,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, num_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FOSZYxrMqhc"
   },
   "source": [
    "# Model\n",
    "- TransformerEncoderLayer:\n",
    "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "  - Parameters:\n",
    "    - d_model: the number of expected features of the input (required).\n",
    "\n",
    "    - nhead: the number of heads of the multiheadattention models (required).\n",
    "\n",
    "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
    "\n",
    "    - dropout: the dropout value (default=0.1).\n",
    "\n",
    "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
    "\n",
    "- TransformerEncoder:\n",
    "  - TransformerEncoder is a stack of N transformer encoder layers\n",
    "  - Parameters:\n",
    "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "\n",
    "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "\n",
    "    - norm: the layer normalization component (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SignLanguageModel(nn.Module):\n",
    "    def __init__(self, num_classes, emg_input_dim=8, imu_input_dim=10, hidden_dim=128):\n",
    "        super(SignLanguageModel, self).__init__()\n",
    "        self.emg_encoder = nn.LSTM(emg_input_dim, hidden_dim, batch_first=True)\n",
    "        self.imu_encoder = nn.LSTM(imu_input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # Concatenating features\n",
    "\n",
    "    def forward(self, emg_data, imu_data):\n",
    "        _, (emg_features, _) = self.emg_encoder(emg_data)\n",
    "        _, (imu_features, _) = self.imu_encoder(imu_data)\n",
    "        \n",
    "        # Concatenate features from the last hidden state of both encoders\n",
    "        combined_features = torch.cat((emg_features[-1], imu_features[-1]), dim=1)\n",
    "        output = self.fc(combined_features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EmNGNr796xiS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_dim=8, d_model=224, ff_dim=256, num_heads=2, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Project the dimension of features from that of input into an enhanced feature space\n",
    "        self.prenet = nn.Linear(input_dim, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, dim_feedforward=d_model*2, nhead=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prenet(x)  # Apply prenet\n",
    "        x = self.encoder(x)  # Transformer encoder\n",
    "        x = x.transpose(1, 2)  # Change (batch, seq_len, features) to (batch, features, seq_len)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Assuming 8 features per timestep and the sequence length is the same for all samples\n",
    "# model = TransformerModel(input_dim=8, num_heads=2, ff_dim=256, num_classes=len(np.unique(dataset.labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7yX8JinM5Ly"
   },
   "source": [
    "# Learning rate schedule\n",
    "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
    "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
    "- The warmup schedule\n",
    "  - Set learning rate to 0 in the beginning.\n",
    "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ykt0N1nVJJi2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "\toptimizer: Optimizer,\n",
    "\tnum_warmup_steps: int,\n",
    "\tnum_training_steps: int,\n",
    "\tnum_cycles: float = 0.5,\n",
    "\tlast_epoch: int = -1,\n",
    "):\n",
    "\t\"\"\"\n",
    "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
    "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
    "\tinitial lr set in the optimizer.\n",
    "\n",
    "\tArgs:\n",
    "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
    "\t\tThe optimizer for which to schedule the learning rate.\n",
    "\t\tnum_warmup_steps (:obj:`int`):\n",
    "\t\tThe number of steps for the warmup phase.\n",
    "\t\tnum_training_steps (:obj:`int`):\n",
    "\t\tThe total number of training steps.\n",
    "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
    "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
    "\t\tfollowing a half-cosine).\n",
    "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
    "\t\tThe index of the last epoch when resuming training.\n",
    "\n",
    "\tReturn:\n",
    "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "\t\"\"\"\n",
    "\tdef lr_lambda(current_step):\n",
    "\t\t# Warmup\n",
    "\t\tif current_step < num_warmup_steps:\n",
    "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
    "\t\t# decadence\n",
    "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
    "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
    "\t\t)\n",
    "\t\treturn max(\n",
    "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
    "\t\t)\n",
    "\n",
    "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LN2XkteM_uH"
   },
   "source": [
    "# Model Function\n",
    "- Model forward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(batch, model, criterion, device):\n",
    "    emg_data, imu_data, labels = batch\n",
    "    emg_data = emg_data.to(device)\n",
    "    imu_data = imu_data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(emg_data, imu_data)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    preds = outputs.argmax(dim=1)\n",
    "    accuracy = (preds == labels).float().mean()\n",
    "\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwM_xyOtNCI2"
   },
   "source": [
    "# Validate\n",
    "- Calculate accuracy of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hZOaHCCblegt"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def valid(dataloader, model, criterion, device):\n",
    "    \"\"\"Validate on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\"sample\")\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy.item()\n",
    "\n",
    "        pbar.update(dataloader.batch_size)\n",
    "        pbar.set_postfix(\n",
    "            loss=f\"{running_loss / (i+1):.2f}\",\n",
    "            accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
    "        )\n",
    "\n",
    "    pbar.close()\n",
    "    model.train()\n",
    "\n",
    "    return running_accuracy / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ne9G-eNEdG"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "H4V6JgNMlrzR",
    "outputId": "5731ae50-9e9e-4740-985f-92f31d4d4b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cpu now!\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   2% 8/500 [04:06<3:37:56, 26.58s/ step, accuracy=0.00, loss=6.95, step=8]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 85\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(emg_dir, imu_dir, save_path, batch_size, n_workers, valid_steps, warmup_steps, total_steps, save_steps, pretrained_path)\u001b[0m\n\u001b[1;32m     82\u001b[0m     train_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(train_loader)\n\u001b[1;32m     83\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_iterator)\n\u001b[0;32m---> 85\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     87\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m, in \u001b[0;36mmodel_fn\u001b[0;34m(batch, model, criterion, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m imu_data \u001b[38;5;241m=\u001b[39m imu_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43memg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimu_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     10\u001b[0m preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m, in \u001b[0;36mSignLanguageModel.forward\u001b[0;34m(self, emg_data, imu_data)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, emg_data, imu_data):\n\u001b[0;32m---> 11\u001b[0m     _, (emg_features, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memg_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43memg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     _, (imu_features, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimu_encoder(imu_data)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Concatenate features from the last hidden state of both encoders\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from get_emg_dataloader import get_emg_dataloader\n",
    "# from your_model_file import TransformerModel, model_fn, valid\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"arguments\"\"\"\n",
    "    config = {\n",
    "        # \"data_dir\": \"./emg_data\",\n",
    "        # \"data_dir\": \"/tmp/dataset/emg_data/emg_data\",\n",
    "        \"emg_dir\": \"/tmp/dataset/emg_data/emg_data\",\n",
    "        \"imu_dir\": \"/tmp/dataset/imu_data/imu_data\",\n",
    "        \"save_path\": \"model.ckpt\",\n",
    "        \"batch_size\": 32,\n",
    "        \"n_workers\": 2,\n",
    "        \"valid_steps\": 500,\n",
    "        \"warmup_steps\": 500,\n",
    "        \"save_steps\": 2500,\n",
    "        \"total_steps\": 7500,\n",
    "        \"pretrained_path\": None,  # 可以设置为预先训练好的模型路径\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def main(\n",
    "#     data_dir,\n",
    "    emg_dir,\n",
    "    imu_dir,\n",
    "    save_path,\n",
    "    batch_size,\n",
    "    n_workers,\n",
    "    valid_steps,\n",
    "    warmup_steps,\n",
    "    total_steps,\n",
    "    save_steps,\n",
    "    pretrained_path=None,\n",
    "):\n",
    "    \"\"\"Main function.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "    train_loader, valid_loader, num_classes = get_fused_dataloader(emg_dir, imu_dir, batch_size, n_workers)\n",
    "    print(f\"[Info]: Finish loading data!\", flush=True)\n",
    "\n",
    "    model = SignLanguageModel(num_classes=num_classes).to(device)\n",
    "#     model = SignLanguageModel(input_dim=EMG_DIM, hidden_dim=HIDDEN_DIM, num_classes=num_classes).to(device)\n",
    "#     model = TransformerModel(num_classes=num_classes).to(device)\n",
    "\n",
    "    if pretrained_path:\n",
    "        model.load_state_dict(torch.load(pretrained_path, map_location=device))\n",
    "        print(\"[Info]: Pretrained model loaded!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n",
    "\n",
    "    print(f\"[Info]: Finish creating model!\", flush=True)\n",
    "\n",
    "    best_accuracy = -1.0\n",
    "    best_state_dict = None\n",
    "\n",
    "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "    \n",
    "    for step in range(total_steps):\n",
    "        try:\n",
    "            batch = next(iter(train_loader))\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            batch = next(train_iterator)\n",
    "\n",
    "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_postfix(\n",
    "            loss=f\"{loss.item():.2f}\",\n",
    "            accuracy=f\"{accuracy:.2f}\",\n",
    "            step=step + 1,\n",
    "        )\n",
    "\n",
    "        if (step + 1) % valid_steps == 0:\n",
    "            pbar.close()\n",
    "            valid_accuracy = valid(valid_loader, model, criterion, device)\n",
    "            if valid_accuracy > best_accuracy:\n",
    "                best_accuracy = valid_accuracy\n",
    "                best_state_dict = model.state_dict()\n",
    "\n",
    "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
    "\n",
    "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
    "            torch.save(best_state_dict, save_path)\n",
    "            print(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(**parse_args())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLatBYAhNNMx"
   },
   "source": [
    "# Inference\n",
    "\n",
    "## Dataset of inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efS4pCmAJXJH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "\tdef __init__(self, data_dir):\n",
    "\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n",
    "\t\tmetadata = json.load(testdata_path.open())\n",
    "\t\tself.data_dir = data_dir\n",
    "\t\tself.data = metadata[\"utterances\"]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tutterance = self.data[index]\n",
    "\t\tfeat_path = utterance[\"feature_path\"]\n",
    "\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n",
    "\n",
    "\t\treturn feat_path, mel\n",
    "\n",
    "\n",
    "def inference_collate_batch(batch):\n",
    "\t\"\"\"Collate a batch of data.\"\"\"\n",
    "\tfeat_paths, mels = zip(*batch)\n",
    "\n",
    "\treturn feat_paths, torch.stack(mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl0WnYwxNK_S"
   },
   "source": [
    "## Main funcrion of Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "f55456f66b2f4194bf09e5bb2d0aa056",
      "1ec97c36e27e4c4e9e363e5ec9c18d91",
      "dfd5ff417c64471b89a92e2507b5862e",
      "c3606c4a79484900b1908e5adc8e03e8",
      "bece48b02f684ddaa1e879adb7473594",
      "6b7aea63809148d2bd14132d841030e7",
      "003e9920d1614b658084ac73c0c7a433",
      "d4efe5163fb346e7ac692657aee81c1f",
      "3941431284af4546a75d3fff846a1d2d",
      "4c884a89a2e648cda64bdbbd9a69379c",
      "59856358c1954fbc9eae3b77b63e82fc"
     ]
    },
    "id": "i8SAbuXEJb2A",
    "outputId": "464f9a64-efc3-4d79-9845-36bb881f730f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Use cuda now!\n",
      "[Info]: Finish loading data!\n",
      "[Info]: Finish creating model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55456f66b2f4194bf09e5bb2d0aa056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def parse_args():\n",
    "\t\"\"\"arguments\"\"\"\n",
    "\tconfig = {\n",
    "\t\t\"data_dir\": \"./Dataset\",\n",
    "\t\t\"model_path\": \"./model.ckpt\",\n",
    "\t\t\"output_path\": \"./output.csv\",\n",
    "\t}\n",
    "\n",
    "\treturn config\n",
    "\n",
    "\n",
    "def main(\n",
    "\tdata_dir,\n",
    "\tmodel_path,\n",
    "\toutput_path,\n",
    "):\n",
    "\t\"\"\"Main function.\"\"\"\n",
    "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tprint(f\"[Info]: Use {device} now!\")\n",
    "\n",
    "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
    "\tmapping = json.load(mapping_path.open())\n",
    "\n",
    "\tdataset = InferenceDataset(data_dir)\n",
    "\tdataloader = DataLoader(\n",
    "\t\tdataset,\n",
    "\t\tbatch_size=1,\n",
    "\t\tshuffle=False,\n",
    "\t\tdrop_last=False,\n",
    "\t\tnum_workers=8,\n",
    "\t\tcollate_fn=inference_collate_batch,\n",
    "\t)\n",
    "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
    "\n",
    "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
    "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
    "\tmodel.load_state_dict(torch.load(model_path))\n",
    "\tmodel.eval()\n",
    "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
    "\n",
    "\tresults = [[\"Id\", \"Category\"]]\n",
    "\tfor feat_paths, mels in tqdm(dataloader):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tmels = mels.to(device)\n",
    "\t\t\touts = model(mels)\n",
    "\t\t\tpreds = outs.argmax(1).cpu().numpy()\n",
    "\t\t\tfor feat_path, pred in zip(feat_paths, preds):\n",
    "\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
    "\n",
    "\twith open(output_path, 'w', newline='') as csvfile:\n",
    "\t\twriter = csv.writer(csvfile)\n",
    "\t\twriter.writerows(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain(**parse_args())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003e9920d1614b658084ac73c0c7a433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ec97c36e27e4c4e9e363e5ec9c18d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b7aea63809148d2bd14132d841030e7",
      "placeholder": "​",
      "style": "IPY_MODEL_003e9920d1614b658084ac73c0c7a433",
      "value": "100%"
     }
    },
    "3941431284af4546a75d3fff846a1d2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c884a89a2e648cda64bdbbd9a69379c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59856358c1954fbc9eae3b77b63e82fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b7aea63809148d2bd14132d841030e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bece48b02f684ddaa1e879adb7473594": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3606c4a79484900b1908e5adc8e03e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c884a89a2e648cda64bdbbd9a69379c",
      "placeholder": "​",
      "style": "IPY_MODEL_59856358c1954fbc9eae3b77b63e82fc",
      "value": " 8000/8000 [00:29&lt;00:00, 201.09it/s]"
     }
    },
    "d4efe5163fb346e7ac692657aee81c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfd5ff417c64471b89a92e2507b5862e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4efe5163fb346e7ac692657aee81c1f",
      "max": 8000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3941431284af4546a75d3fff846a1d2d",
      "value": 8000
     }
    },
    "f55456f66b2f4194bf09e5bb2d0aa056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ec97c36e27e4c4e9e363e5ec9c18d91",
       "IPY_MODEL_dfd5ff417c64471b89a92e2507b5862e",
       "IPY_MODEL_c3606c4a79484900b1908e5adc8e03e8"
      ],
      "layout": "IPY_MODEL_bece48b02f684ddaa1e879adb7473594"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
