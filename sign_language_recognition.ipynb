{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "eDNE_QCO7YI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtnmxx_S7hFL",
        "outputId": "8b7d898c-c0e1-4737-fffc-39e931c3832c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'drive/MyDrive/emg_imu_data.zip'\n"
      ],
      "metadata": {
        "id": "CRID4Xsw7wN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENWVAUDVJtVY"
      },
      "source": [
        "## Fix Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E6burzCXIyuA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(87)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7dVbxW2LASN"
      },
      "source": [
        "# Data\n",
        "\n",
        "## Dataset\n",
        "- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n",
        "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n",
        "- We randomly select 600 speakers from Voxceleb2.\n",
        "- Then preprocess the raw waveforms into mel-spectrograms.\n",
        "\n",
        "- Args:\n",
        "  - data_dir: The path to the data directory.\n",
        "  - metadata_path: The path to the metadata.\n",
        "  - segment_len: The length of audio segment for training.\n",
        "- The architecture of data directory \\\\\n",
        "  - data directory \\\\\n",
        "  |---- metadata.json \\\\\n",
        "  |---- testdata.json \\\\\n",
        "  |---- mapping.json \\\\\n",
        "  |---- uttr-{random string}.pt \\\\\n",
        "\n",
        "- The information in metadata\n",
        "  - \"n_mels\": The dimention of mel-spectrogram.\n",
        "  - \"speakers\": A dictionary.\n",
        "    - Key: speaker ids.\n",
        "    - value: \"feature_path\" and \"mel_len\"\n",
        "\n",
        "\n",
        "For efficiency, we segment the mel-spectrograms into segments in the traing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8ozJ3rEh6xiR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class EMGDataset(Dataset):\n",
        "    def __init__(self, directory, seq_length=790, scaler=None):\n",
        "        self.directory = directory\n",
        "        self.seq_length = seq_length\n",
        "        self.files = []\n",
        "        self.labels = []\n",
        "        self.scaler = scaler  # 将预先计算好的Scaler传入\n",
        "\n",
        "        for f in os.listdir(directory):\n",
        "            if f.endswith(\"_emg.txt\"):\n",
        "                filepath = os.path.join(directory, f)\n",
        "                if os.path.getsize(filepath) > 0:\n",
        "                    self.files.append(filepath)\n",
        "                    self.labels.append(f.split('_')[0])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
        "        self.labels = torch.from_numpy(self.labels).long()\n",
        "\n",
        "        self.num_classes=len(np.unique(self.labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.files[idx]\n",
        "        emg_signals = np.loadtxt(filepath)\n",
        "        if emg_signals.shape[0] < self.seq_length:\n",
        "            pad = np.zeros((self.seq_length - emg_signals.shape[0], emg_signals.shape[1]))\n",
        "            emg_signals = np.vstack([emg_signals, pad])\n",
        "        elif emg_signals.shape[0] > self.seq_length:\n",
        "            emg_signals = emg_signals[:self.seq_length, :]\n",
        "\n",
        "        if self.scaler:\n",
        "            emg_signals = self.scaler.transform(emg_signals)  # 使用预先拟合的Scaler进行转换\n",
        "\n",
        "        emg_signals = torch.from_numpy(emg_signals).float()\n",
        "        return emg_signals, self.labels[idx]\n",
        "\n",
        "    def get_num_classes(self):\n",
        "\t\t    return self.num_classes\n",
        "\n",
        "\n",
        "\n",
        "# # Assuming 'path_to_your_directory' is the path to your data\n",
        "# dataset = EMGDataset('path_to_your_directory')\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 计算sacler"
      ],
      "metadata": {
        "id": "zyjde_c2KuO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def incremental_mean_std(directory, seq_length=790):\n",
        "    mean = np.zeros((seq_length, 8))  # 假设每个样本有8个特征\n",
        "    M2 = np.zeros((seq_length, 8))\n",
        "    n = 0\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\"_emg.txt\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            if os.path.getsize(filepath) > 0:\n",
        "                data = np.loadtxt(filepath)\n",
        "                if data.size == 0:  # 检查数据是否为空\n",
        "                    continue\n",
        "                if data.shape[0] < seq_length:\n",
        "                    # 填充不足的数据\n",
        "                    pad = np.zeros((seq_length - data.shape[0], data.shape[1]))\n",
        "                    data = np.vstack([data, pad])\n",
        "                elif data.shape[0] > seq_length:\n",
        "                    # 截断超出的数据\n",
        "                    data = data[:seq_length, :]\n",
        "                n += 1\n",
        "                delta = data - mean\n",
        "                mean += delta / n\n",
        "                M2 += delta * (data - mean)\n",
        "\n",
        "    std = np.sqrt(M2 / n) if n > 1 else np.sqrt(M2)\n",
        "    return mean, std\n",
        "\n",
        "# directory = 'emg_data'\n",
        "# mean, std = incremental_mean_std(directory)\n",
        "\n",
        "# 用得到的 mean 和 std 来创建一个 StandardScaler-like 的类\n",
        "class CustomScaler:\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def transform(self, X):\n",
        "        return (X - self.mean) / self.std\n"
      ],
      "metadata": {
        "id": "oM2uk0RLKtgO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'emg_data'\n",
        "mean, std = incremental_mean_std(directory)\n",
        "scaler = CustomScaler(mean, std)"
      ],
      "metadata": {
        "id": "d7GDv3MNK4Ou"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# 从文件加载scaler对象\n",
        "with open('drive/MyDrive/scaler.pkl', 'rb') as f:\n",
        "    loaded_scaler = pickle.load(f)\n",
        "\n",
        "    scaler = loaded_scaler"
      ],
      "metadata": {
        "id": "EOAlzmBqPDhh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用加载的scaler来转换数据\n",
        "# transformed_data = loaded_scaler.transform(new_data)"
      ],
      "metadata": {
        "id": "H_KOJtnhPHck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = EMGDataset(directory=directory, scaler=scaler)"
      ],
      "metadata": {
        "id": "zbxB6Re5K-AH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory='emg_data'\n",
        "# scaler = compute_statistics(directory)\n",
        "\n",
        "dataset = EMGDataset(directory=directory, scaler=scaler)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "pYx62gBv96if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 确定seq_length\n",
        "确定seq_length"
      ],
      "metadata": {
        "id": "BPNw4tAcbG4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "lengths0 = []\n",
        "lengths1 = []\n",
        "def analyze_emg_lengths(directory):\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\"_emg.txt\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            try:\n",
        "                emg_signals = np.loadtxt(filepath)\n",
        "                if emg_signals.shape[0]!=0:\n",
        "                  lengths0.append(emg_signals.shape[0])\n",
        "                  lengths1.append(emg_signals.shape[1])\n",
        "\n",
        "            except:\n",
        "                # Handling empty or corrupted files\n",
        "                print(f\"Could not load data from {filename}\")\n",
        "    return lengths0, lengths1\n",
        "\n",
        "# Assuming 'path_to_your_directory' is the path to your data\n",
        "# directory = 'emg_data'\n",
        "# lengths = analyze_emg_lengths(directory)\n",
        "\n",
        "# # Calculate statistics\n",
        "# if lengths0:\n",
        "#     min_length0 = np.min(lengths0)\n",
        "#     max_length0 = np.max(lengths0)\n",
        "#     avg_length0 = np.mean(lengths0)\n",
        "#     median_length0 = np.median(lengths0)\n",
        "\n",
        "#     min_length1 = np.min(lengths1)\n",
        "#     max_length1 = np.max(lengths1)\n",
        "#     avg_length1 = np.mean(lengths1)\n",
        "#     median_length1 = np.median(lengths1)\n",
        "\n",
        "#     print(f\"Minimum length: {min_length0}, {min_length1}\")\n",
        "#     print(f\"Maximum length: {max_length0}， {max_length1}\")\n",
        "#     print(f\"Average length: {avg_length0:.2f}, {avg_length1:.2f}\")\n",
        "#     print(f\"Median length: {median_length0}, {median_length1}\")\n",
        "# else:\n",
        "#     print(\"No data available to analyze.\")\n"
      ],
      "metadata": {
        "id": "r06nf5k2KA_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "668hverTMlGN"
      },
      "source": [
        "## Dataloader\n",
        "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
        "- Create dataloader to iterate the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler=scaler\n",
        "scaler=None"
      ],
      "metadata": {
        "id": "XO7Dmmsm8PYD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def emg_collate_batch(batch):\n",
        "    data, labels = zip(*batch)\n",
        "    return torch.stack(data), torch.tensor(labels)\n",
        "\n",
        "def get_emg_dataloader(data_dir, batch_size, n_workers):\n",
        "    dataset = EMGDataset(directory=data_dir, scaler=scaler)\n",
        "    num_classes = dataset.get_num_classes()\n",
        "    # 分割数据集为训练集和验证集\n",
        "    train_len = int(0.9 * len(dataset))\n",
        "    lengths = [train_len, len(dataset) - train_len]\n",
        "    train_set, valid_set = random_split(dataset, lengths)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "        num_workers=n_workers,\n",
        "        pin_memory=True,\n",
        "        collate_fn=emg_collate_batch,\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_set,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=n_workers,\n",
        "        drop_last=True,\n",
        "        pin_memory=True,\n",
        "        collate_fn=emg_collate_batch,\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader, num_classes\n"
      ],
      "metadata": {
        "id": "QrOnyMOidsem"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FOSZYxrMqhc"
      },
      "source": [
        "# Model\n",
        "- TransformerEncoderLayer:\n",
        "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "  - Parameters:\n",
        "    - d_model: the number of expected features of the input (required).\n",
        "\n",
        "    - nhead: the number of heads of the multiheadattention models (required).\n",
        "\n",
        "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "\n",
        "    - dropout: the dropout value (default=0.1).\n",
        "\n",
        "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "- TransformerEncoder:\n",
        "  - TransformerEncoder is a stack of N transformer encoder layers\n",
        "  - Parameters:\n",
        "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "\n",
        "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "\n",
        "    - norm: the layer normalization component (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EmNGNr796xiS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, ff_dim, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=ff_dim, batch_first=True)\n",
        "        # self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads, dim_feedforward=input_dim*2)\n",
        "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1, 0, 2)  # PyTorch transformer expects input as (seq_len, batch, features)\n",
        "        x = self.encoder(x)\n",
        "        x = x.permute(1, 2, 0)  # Revert to (batch, features, seq_len) for pooling\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Assuming 8 features per timestep and the sequence length is the same for all samples\n",
        "# model = TransformerModel(input_dim=8, num_heads=2, ff_dim=256, num_classes=len(np.unique(dataset.labels)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXZ5B0EKJGs8"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# class Classifier(nn.Module):\n",
        "# \tdef __init__(self, d_model=224, n_spks=600, dropout=0.1):\n",
        "# \t\tsuper().__init__()\n",
        "# \t\t# Project the dimension of features from that of input into d_model.\n",
        "# \t\tself.prenet = nn.Linear(40, d_model)\n",
        "# \t\t# TODO:\n",
        "# \t\t#   Change Transformer to Conformer.\n",
        "# \t\t#   https://arxiv.org/abs/2005.08100\n",
        "# \t\tself.encoder_layer = nn.TransformerEncoderLayer(\n",
        "# \t\t\td_model=d_model, dim_feedforward=d_model*2, nhead=2, dropout=dropout\n",
        "# \t\t)\n",
        "# \t\tself.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
        "\n",
        "# \t\t# Project the the dimension of features from d_model into speaker nums.\n",
        "# \t\tself.pred_layer = nn.Sequential(\n",
        "# \t\t\tnn.BatchNorm1d(d_model),\n",
        "# \t\t\tnn.Linear(d_model, n_spks),\n",
        "# \t\t)\n",
        "\n",
        "# \tdef forward(self, mels):\n",
        "# \t\t\"\"\"\n",
        "# \t\targs:\n",
        "# \t\t\tmels: (batch size, length, 40)\n",
        "# \t\treturn:\n",
        "# \t\t\tout: (batch size, n_spks)\n",
        "# \t\t\"\"\"\n",
        "# \t\t# out: (batch size, length, d_model)\n",
        "# \t\tout = self.prenet(mels)\n",
        "# \t\t# out: (length, batch size, d_model)\n",
        "# \t\tout = out.permute(1, 0, 2)\n",
        "# \t\t# The encoder layer expect features in the shape of (length, batch size, d_model).\n",
        "# \t\tout = self.encoder_layer(out)\n",
        "# \t\t# out: (batch size, length, d_model)\n",
        "# \t\tout = out.transpose(0, 1)\n",
        "# \t\t# mean pooling\n",
        "# \t\tstats = out.mean(dim=1)\n",
        "\n",
        "# \t\t# out: (batch, n_spks)\n",
        "# \t\tout = self.pred_layer(stats)\n",
        "# \t\treturn out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yX8JinM5Ly"
      },
      "source": [
        "# Learning rate schedule\n",
        "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
        "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
        "- The warmup schedule\n",
        "  - Set learning rate to 0 in the beginning.\n",
        "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ykt0N1nVJJi2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tnum_training_steps: int,\n",
        "\tnum_cycles: float = 0.5,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\t\"\"\"\n",
        "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "\tinitial lr set in the optimizer.\n",
        "\n",
        "\tArgs:\n",
        "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
        "\t\tThe optimizer for which to schedule the learning rate.\n",
        "\t\tnum_warmup_steps (:obj:`int`):\n",
        "\t\tThe number of steps for the warmup phase.\n",
        "\t\tnum_training_steps (:obj:`int`):\n",
        "\t\tThe total number of training steps.\n",
        "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "\t\tfollowing a half-cosine).\n",
        "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "\t\tThe index of the last epoch when resuming training.\n",
        "\n",
        "\tReturn:\n",
        "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "\t\"\"\"\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "\t\t)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LN2XkteM_uH"
      },
      "source": [
        "# Model Function\n",
        "- Model forward function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "    \"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "    # 解包批数据\n",
        "    data, labels = batch\n",
        "    # 将数据和标签转移到指定设备（例如 GPU）\n",
        "    data = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # 通过模型进行前向传播得到输出\n",
        "    outs = model(data)\n",
        "\n",
        "    # 计算损失\n",
        "    loss = criterion(outs, labels)\n",
        "\n",
        "    # 计算预测的类别（最高得分的类别）\n",
        "    preds = outs.argmax(1)\n",
        "    # 计算准确率\n",
        "    accuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "    return loss, accuracy\n"
      ],
      "metadata": {
        "id": "d-AWw5v5hYpB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwM_xyOtNCI2"
      },
      "source": [
        "# Validate\n",
        "- Calculate accuracy of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def valid(dataloader, model, criterion, device):\n",
        "    \"\"\"Validate on validation set.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "    pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\"sample\")\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        with torch.no_grad():\n",
        "            loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "            running_loss += loss.item()\n",
        "            running_accuracy += accuracy.item()\n",
        "\n",
        "        pbar.update(dataloader.batch_size)\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{running_loss / (i+1):.2f}\",\n",
        "            accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "        )\n",
        "\n",
        "    pbar.close()\n",
        "    model.train()\n",
        "\n",
        "    return running_accuracy / len(dataloader)\n"
      ],
      "metadata": {
        "id": "hZOaHCCblegt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ne9G-eNEdG"
      },
      "source": [
        "# Main function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"arguments\"\"\"\n",
        "    config = {\n",
        "        \"data_dir\": \"./emg_data\",\n",
        "        \"save_path\": \"model.ckpt\",\n",
        "        \"batch_size\": 32,\n",
        "        \"n_workers\": 2,\n",
        "        \"valid_steps\": 500,\n",
        "        \"warmup_steps\": 500,\n",
        "        \"save_steps\": 2500,\n",
        "        \"total_steps\": 7500,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "def main(\n",
        "    data_dir,\n",
        "    save_path,\n",
        "    batch_size,\n",
        "    n_workers,\n",
        "    valid_steps,\n",
        "    warmup_steps,\n",
        "    total_steps,\n",
        "    save_steps,\n",
        "):\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "    train_loader, valid_loader, num_classes = get_emg_dataloader(data_dir, batch_size, n_workers)\n",
        "    train_iterator = iter(train_loader)\n",
        "    print(f\"[Info]: Finish loading data!\", flush=True)\n",
        "\n",
        "    model = TransformerModel(input_dim=8, num_heads=2, ff_dim=256, num_classes=num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)\n",
        "\n",
        "    print(f\"[Info]: Finish creating model!\", flush=True)\n",
        "\n",
        "    best_accuracy = -1.0\n",
        "    best_state_dict = None\n",
        "\n",
        "    pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    for step in range(total_steps):\n",
        "        try:\n",
        "            batch = next(train_iterator)\n",
        "        except StopIteration:\n",
        "            train_iterator = iter(train_loader)\n",
        "            batch = next(train_iterator)\n",
        "\n",
        "        loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        pbar.update()\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{loss.item():.2f}\",\n",
        "            accuracy=f\"{accuracy:.2f}\",\n",
        "            step=step + 1,\n",
        "        )\n",
        "\n",
        "        if (step + 1) % valid_steps == 0:\n",
        "            pbar.close()\n",
        "            valid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "            if valid_accuracy > best_accuracy:\n",
        "                best_accuracy = valid_accuracy\n",
        "                best_state_dict = model.state_dict()\n",
        "\n",
        "            pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "        if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "            torch.save(best_state_dict, save_path)\n",
        "            print(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(**parse_args())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "H4V6JgNMlrzR",
        "outputId": "5731ae50-9e9e-4740-985f-92f31d4d4b23"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info]: Use cuda now!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 500/500 [00:25<00:00, 19.61 step/s, accuracy=0.00, loss=6.07, step=500]\n",
            "Valid: 100% 7616/7622 [00:06<00:00, 1098.77sample/s, accuracy=0.01, loss=6.03]\n",
            "Train: 100% 500/500 [00:24<00:00, 20.62 step/s, accuracy=0.03, loss=6.02, step=1000]\n",
            "Valid: 100% 7616/7622 [00:06<00:00, 1107.92sample/s, accuracy=0.01, loss=5.98]\n",
            "Train: 100% 500/500 [00:24<00:00, 20.54 step/s, accuracy=0.03, loss=5.74, step=1500]\n",
            "Valid: 100% 7616/7622 [00:06<00:00, 1095.29sample/s, accuracy=0.01, loss=5.93]\n",
            "Train: 100% 500/500 [00:23<00:00, 21.26 step/s, accuracy=0.03, loss=5.87, step=2000]\n",
            "Valid: 100% 7616/7622 [00:06<00:00, 1134.44sample/s, accuracy=0.02, loss=5.88]\n",
            "Train: 100% 500/500 [00:24<00:00, 20.36 step/s, accuracy=0.00, loss=5.77, step=2500]\n",
            "Valid: 100% 7616/7622 [00:12<00:00, 616.31sample/s, accuracy=0.02, loss=5.83]\n",
            "Train:   1% 6/500 [00:00<00:15, 31.80 step/s, accuracy=0.03, loss=5.93, step=2506]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2500, best model saved. (accuracy=0.0183)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 500/500 [00:24<00:00, 20.43 step/s, accuracy=0.03, loss=6.13, step=3000]\n",
            "Valid: 100% 7616/7622 [00:08<00:00, 863.48sample/s, accuracy=0.02, loss=5.80] \n",
            "Train: 100% 500/500 [00:22<00:00, 22.13 step/s, accuracy=0.03, loss=5.62, step=3500]\n",
            "Valid: 100% 7616/7622 [00:09<00:00, 843.51sample/s, accuracy=0.02, loss=5.77] \n",
            "Train: 100% 500/500 [00:21<00:00, 23.04 step/s, accuracy=0.00, loss=5.98, step=4000]\n",
            "Valid: 100% 7616/7622 [00:08<00:00, 868.44sample/s, accuracy=0.02, loss=5.74] \n",
            "Train: 100% 500/500 [00:22<00:00, 22.43 step/s, accuracy=0.00, loss=5.51, step=4500]\n",
            "Valid: 100% 7616/7622 [00:08<00:00, 900.82sample/s, accuracy=0.02, loss=5.73] \n",
            "Train: 100% 500/500 [00:23<00:00, 21.40 step/s, accuracy=0.00, loss=6.02, step=5000]\n",
            "Valid: 100% 7616/7622 [00:08<00:00, 875.19sample/s, accuracy=0.02, loss=5.71] \n",
            "Train:   2% 8/500 [00:00<00:09, 54.08 step/s, accuracy=0.00, loss=5.92, step=5008]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5000, best model saved. (accuracy=0.0202)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 500/500 [00:22<00:00, 22.57 step/s, accuracy=0.06, loss=5.74, step=5500]\n",
            "Valid: 100% 7616/7622 [00:08<00:00, 882.27sample/s, accuracy=0.02, loss=5.70] \n",
            "Train:  70% 351/500 [00:14<00:08, 18.51 step/s, accuracy=0.00, loss=5.53, step=5851]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3cb02ea3eb1b>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-3cb02ea3eb1b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(data_dir, save_path, batch_size, n_workers, valid_steps, warmup_steps, total_steps, save_steps)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtrain_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 示例"
      ],
      "metadata": {
        "id": "OMzPtfLqc5v7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usv9s-CuJSG7",
        "outputId": "74aaf02c-5e1c-4efa-aa1f-a0de788c2975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Train:  80% 1593/2000 [00:36<00:06, 64.73 step/s, accuracy=0.31, loss=3.69, step=1593]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.04 step/s, accuracy=0.41, loss=2.86, step=2000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1561.83 uttr/s, accuracy=0.34, loss=3.13]\n",
            "Train: 100% 2000/2000 [00:49<00:00, 40.44 step/s, accuracy=0.38, loss=3.04, step=4000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1138.34 uttr/s, accuracy=0.48, loss=2.38]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 44.40 step/s, accuracy=0.44, loss=2.84, step=6000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1519.46 uttr/s, accuracy=0.53, loss=2.09]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 44.15 step/s, accuracy=0.50, loss=2.34, step=8000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1864.74 uttr/s, accuracy=0.58, loss=1.89]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 43.97 step/s, accuracy=0.72, loss=1.34, step=1e+4]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1689.51 uttr/s, accuracy=0.59, loss=1.81]\n",
            "Train:   1% 11/2000 [00:00<00:38, 51.57 step/s, accuracy=0.72, loss=1.38, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10000, best model saved. (accuracy=0.5922)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:45<00:00, 44.19 step/s, accuracy=0.69, loss=1.61, step=12000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1173.37 uttr/s, accuracy=0.61, loss=1.71]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.54 step/s, accuracy=0.69, loss=1.06, step=14000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1175.19 uttr/s, accuracy=0.63, loss=1.66]\n",
            "Train: 100% 2000/2000 [00:50<00:00, 39.50 step/s, accuracy=0.91, loss=0.55, step=16000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1601.51 uttr/s, accuracy=0.66, loss=1.51]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.87 step/s, accuracy=0.66, loss=1.52, step=18000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1833.34 uttr/s, accuracy=0.66, loss=1.48]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.05 step/s, accuracy=0.84, loss=0.63, step=2e+4]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1851.15 uttr/s, accuracy=0.69, loss=1.39]\n",
            "Train:   1% 12/2000 [00:00<00:34, 56.96 step/s, accuracy=0.84, loss=0.83, step=2e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20000, best model saved. (accuracy=0.6870)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:44<00:00, 44.62 step/s, accuracy=0.66, loss=1.63, step=22000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1224.47 uttr/s, accuracy=0.68, loss=1.42]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 44.00 step/s, accuracy=0.75, loss=0.90, step=24000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1199.49 uttr/s, accuracy=0.71, loss=1.30]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 43.74 step/s, accuracy=0.72, loss=1.15, step=26000]\n",
            "Valid: 100% 5664/5667 [00:05<00:00, 1033.41 uttr/s, accuracy=0.71, loss=1.30]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 43.54 step/s, accuracy=0.75, loss=1.12, step=28000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1632.32 uttr/s, accuracy=0.72, loss=1.23]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.97 step/s, accuracy=0.66, loss=1.53, step=3e+4]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1852.08 uttr/s, accuracy=0.73, loss=1.20]\n",
            "Train:   0% 9/2000 [00:00<00:46, 42.40 step/s, accuracy=0.78, loss=0.63, step=3e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 30000, best model saved. (accuracy=0.7279)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:44<00:00, 44.67 step/s, accuracy=0.75, loss=0.80, step=32000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1844.36 uttr/s, accuracy=0.72, loss=1.24]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.17 step/s, accuracy=0.75, loss=0.88, step=34000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1224.47 uttr/s, accuracy=0.75, loss=1.15]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.85 step/s, accuracy=0.88, loss=0.65, step=36000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1187.38 uttr/s, accuracy=0.76, loss=1.09]\n",
            "Train: 100% 2000/2000 [00:50<00:00, 39.98 step/s, accuracy=0.75, loss=0.98, step=38000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1801.55 uttr/s, accuracy=0.75, loss=1.09]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.55 step/s, accuracy=0.72, loss=0.97, step=4e+4]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1900.22 uttr/s, accuracy=0.76, loss=1.07]\n",
            "Train:   1% 11/2000 [00:00<00:40, 48.54 step/s, accuracy=0.81, loss=0.81, step=4e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 40000, best model saved. (accuracy=0.7622)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:44<00:00, 45.11 step/s, accuracy=0.78, loss=0.84, step=42000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1827.57 uttr/s, accuracy=0.77, loss=1.04]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.83 step/s, accuracy=0.88, loss=0.49, step=44000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1202.22 uttr/s, accuracy=0.77, loss=1.05]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.08 step/s, accuracy=0.81, loss=0.56, step=46000]\n",
            "Valid: 100% 5664/5667 [00:05<00:00, 1127.59 uttr/s, accuracy=0.77, loss=0.99]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 43.99 step/s, accuracy=0.94, loss=0.31, step=48000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1741.05 uttr/s, accuracy=0.78, loss=0.98]\n",
            "Train: 100% 2000/2000 [00:49<00:00, 40.80 step/s, accuracy=0.88, loss=0.39, step=5e+4]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1829.81 uttr/s, accuracy=0.79, loss=0.97]\n",
            "Train:   1% 11/2000 [00:00<00:39, 49.73 step/s, accuracy=0.91, loss=0.73, step=5e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 50000, best model saved. (accuracy=0.7867)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:44<00:00, 45.15 step/s, accuracy=0.88, loss=0.36, step=52000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1909.14 uttr/s, accuracy=0.79, loss=0.94]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.10 step/s, accuracy=0.88, loss=0.48, step=54000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1750.97 uttr/s, accuracy=0.80, loss=0.93]\n",
            "Train: 100% 2000/2000 [00:45<00:00, 44.23 step/s, accuracy=0.94, loss=0.27, step=56000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1160.96 uttr/s, accuracy=0.80, loss=0.95]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.64 step/s, accuracy=0.91, loss=0.40, step=58000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1162.47 uttr/s, accuracy=0.81, loss=0.89]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.67 step/s, accuracy=0.97, loss=0.13, step=6e+4]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1273.41 uttr/s, accuracy=0.81, loss=0.89]\n",
            "Train:   0% 9/2000 [00:00<00:48, 40.81 step/s, accuracy=0.91, loss=0.28, step=6e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60000, best model saved. (accuracy=0.8097)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:47<00:00, 42.16 step/s, accuracy=0.75, loss=0.73, step=62000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1893.85 uttr/s, accuracy=0.81, loss=0.88]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.35 step/s, accuracy=0.78, loss=0.75, step=64000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1356.35 uttr/s, accuracy=0.82, loss=0.85]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.49 step/s, accuracy=0.84, loss=0.53, step=66000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1177.69 uttr/s, accuracy=0.82, loss=0.83]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.12 step/s, accuracy=0.94, loss=0.17, step=68000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1205.62 uttr/s, accuracy=0.82, loss=0.81]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 46.36 step/s, accuracy=0.97, loss=0.16, step=7e+4]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1507.02 uttr/s, accuracy=0.83, loss=0.81]\n",
            "Train:   0% 9/2000 [00:00<00:43, 45.61 step/s, accuracy=0.84, loss=0.38, step=7e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 70000, best model saved. (accuracy=0.8289)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:47<00:00, 42.38 step/s, accuracy=0.91, loss=0.23, step=72000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1186.61 uttr/s, accuracy=0.83, loss=0.80]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.03 step/s, accuracy=0.91, loss=0.34, step=74000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1812.94 uttr/s, accuracy=0.83, loss=0.78]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.85 step/s, accuracy=0.88, loss=0.36, step=76000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1582.77 uttr/s, accuracy=0.83, loss=0.81]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.36 step/s, accuracy=0.88, loss=0.49, step=78000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1226.51 uttr/s, accuracy=0.83, loss=0.79]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.96 step/s, accuracy=0.88, loss=0.59, step=8e+4]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1169.92 uttr/s, accuracy=0.84, loss=0.77]\n",
            "Train:   0% 8/2000 [00:00<01:07, 29.36 step/s, accuracy=0.97, loss=0.10, step=8e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80000, best model saved. (accuracy=0.8385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:44<00:00, 44.97 step/s, accuracy=0.97, loss=0.16, step=82000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1741.05 uttr/s, accuracy=0.84, loss=0.74]\n",
            "Train: 100% 2000/2000 [00:47<00:00, 41.67 step/s, accuracy=0.97, loss=0.13, step=84000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1409.69 uttr/s, accuracy=0.84, loss=0.75]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.81 step/s, accuracy=0.97, loss=0.12, step=86000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1911.13 uttr/s, accuracy=0.84, loss=0.71]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 44.63 step/s, accuracy=1.00, loss=0.16, step=88000]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1860.13 uttr/s, accuracy=0.84, loss=0.75]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 46.27 step/s, accuracy=1.00, loss=0.16, step=9e+4]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1331.91 uttr/s, accuracy=0.85, loss=0.72]\n",
            "Train:   0% 5/2000 [00:00<01:10, 28.41 step/s, accuracy=0.94, loss=0.25, step=9e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90000, best model saved. (accuracy=0.8501)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100% 2000/2000 [00:43<00:00, 46.41 step/s, accuracy=0.94, loss=0.20, step=92000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1176.20 uttr/s, accuracy=0.85, loss=0.73]\n",
            "Train: 100% 2000/2000 [00:44<00:00, 45.32 step/s, accuracy=0.94, loss=0.08, step=94000]\n",
            "Valid: 100% 5664/5667 [00:04<00:00, 1139.50 uttr/s, accuracy=0.85, loss=0.72]\n",
            "Train: 100% 2000/2000 [00:47<00:00, 42.17 step/s, accuracy=0.91, loss=0.18, step=96000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1915.03 uttr/s, accuracy=0.85, loss=0.73]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.76 step/s, accuracy=0.97, loss=0.12, step=98000]\n",
            "Valid: 100% 5664/5667 [00:02<00:00, 1905.56 uttr/s, accuracy=0.84, loss=0.73]\n",
            "Train: 100% 2000/2000 [00:43<00:00, 45.79 step/s, accuracy=0.97, loss=0.13, step=1e+5]\n",
            "Valid: 100% 5664/5667 [00:03<00:00, 1835.94 uttr/s, accuracy=0.85, loss=0.71]\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100000, best model saved. (accuracy=0.8520)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"./Dataset\",\n",
        "\t\t\"save_path\": \"model.ckpt\",\n",
        "\t\t\"batch_size\": 32,\n",
        "\t\t\"n_workers\": 8,\n",
        "\t\t\"valid_steps\": 2000,\n",
        "\t\t\"warmup_steps\": 1000,\n",
        "\t\t\"save_steps\": 10000,\n",
        "\t\t\"total_steps\": 100000,\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tsave_path,\n",
        "\tbatch_size,\n",
        "\tn_workers,\n",
        "\tvalid_steps,\n",
        "\twarmup_steps,\n",
        "\ttotal_steps,\n",
        "\tsave_steps,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\ttrain_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "\ttrain_iterator = iter(train_loader)\n",
        "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\toptimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "\tscheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\tbest_accuracy = -1.0\n",
        "\tbest_state_dict = None\n",
        "\n",
        "\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "\tfor step in range(total_steps):\n",
        "\t\t# Get data\n",
        "\t\ttry:\n",
        "\t\t\tbatch = next(train_iterator)\n",
        "\t\texcept StopIteration:\n",
        "\t\t\ttrain_iterator = iter(train_loader)\n",
        "\t\t\tbatch = next(train_iterator)\n",
        "\n",
        "\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n",
        "\t\tbatch_loss = loss.item()\n",
        "\t\tbatch_accuracy = accuracy.item()\n",
        "\n",
        "\t\t# Updata model\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tscheduler.step()\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t# Log\n",
        "\t\tpbar.update()\n",
        "\t\tpbar.set_postfix(\n",
        "\t\t\tloss=f\"{batch_loss:.2f}\",\n",
        "\t\t\taccuracy=f\"{batch_accuracy:.2f}\",\n",
        "\t\t\tstep=step + 1,\n",
        "\t\t)\n",
        "\n",
        "\t\t# Do validation\n",
        "\t\tif (step + 1) % valid_steps == 0:\n",
        "\t\t\tpbar.close()\n",
        "\n",
        "\t\t\tvalid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "\n",
        "\t\t\t# keep the best model\n",
        "\t\t\tif valid_accuracy > best_accuracy:\n",
        "\t\t\t\tbest_accuracy = valid_accuracy\n",
        "\t\t\t\tbest_state_dict = model.state_dict()\n",
        "\n",
        "\t\t\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "\t\t# Save the best model so far.\n",
        "\t\tif (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "\t\t\ttorch.save(best_state_dict, save_path)\n",
        "\t\t\tpbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "\tpbar.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(**parse_args())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLatBYAhNNMx"
      },
      "source": [
        "# Inference\n",
        "\n",
        "## Dataset of inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efS4pCmAJXJH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "\tdef __init__(self, data_dir):\n",
        "\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n",
        "\t\tmetadata = json.load(testdata_path.open())\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.data = metadata[\"utterances\"]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tutterance = self.data[index]\n",
        "\t\tfeat_path = utterance[\"feature_path\"]\n",
        "\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "\t\treturn feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "\t\"\"\"Collate a batch of data.\"\"\"\n",
        "\tfeat_paths, mels = zip(*batch)\n",
        "\n",
        "\treturn feat_paths, torch.stack(mels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0WnYwxNK_S"
      },
      "source": [
        "## Main funcrion of Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f55456f66b2f4194bf09e5bb2d0aa056",
            "1ec97c36e27e4c4e9e363e5ec9c18d91",
            "dfd5ff417c64471b89a92e2507b5862e",
            "c3606c4a79484900b1908e5adc8e03e8",
            "bece48b02f684ddaa1e879adb7473594",
            "6b7aea63809148d2bd14132d841030e7",
            "003e9920d1614b658084ac73c0c7a433",
            "d4efe5163fb346e7ac692657aee81c1f",
            "3941431284af4546a75d3fff846a1d2d",
            "4c884a89a2e648cda64bdbbd9a69379c",
            "59856358c1954fbc9eae3b77b63e82fc"
          ]
        },
        "id": "i8SAbuXEJb2A",
        "outputId": "464f9a64-efc3-4d79-9845-36bb881f730f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f55456f66b2f4194bf09e5bb2d0aa056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"./Dataset\",\n",
        "\t\t\"model_path\": \"./model.ckpt\",\n",
        "\t\t\"output_path\": \"./output.csv\",\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tmodel_path,\n",
        "\toutput_path,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\tmapping = json.load(mapping_path.open())\n",
        "\n",
        "\tdataset = InferenceDataset(data_dir)\n",
        "\tdataloader = DataLoader(\n",
        "\t\tdataset,\n",
        "\t\tbatch_size=1,\n",
        "\t\tshuffle=False,\n",
        "\t\tdrop_last=False,\n",
        "\t\tnum_workers=8,\n",
        "\t\tcollate_fn=inference_collate_batch,\n",
        "\t)\n",
        "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
        "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
        "\tmodel.load_state_dict(torch.load(model_path))\n",
        "\tmodel.eval()\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\tresults = [[\"Id\", \"Category\"]]\n",
        "\tfor feat_paths, mels in tqdm(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tmels = mels.to(device)\n",
        "\t\t\touts = model(mels)\n",
        "\t\t\tpreds = outs.argmax(1).cpu().numpy()\n",
        "\t\t\tfor feat_path, pred in zip(feat_paths, preds):\n",
        "\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "\n",
        "\twith open(output_path, 'w', newline='') as csvfile:\n",
        "\t\twriter = csv.writer(csvfile)\n",
        "\t\twriter.writerows(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(**parse_args())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003e9920d1614b658084ac73c0c7a433": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec97c36e27e4c4e9e363e5ec9c18d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7aea63809148d2bd14132d841030e7",
            "placeholder": "​",
            "style": "IPY_MODEL_003e9920d1614b658084ac73c0c7a433",
            "value": "100%"
          }
        },
        "3941431284af4546a75d3fff846a1d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c884a89a2e648cda64bdbbd9a69379c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59856358c1954fbc9eae3b77b63e82fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7aea63809148d2bd14132d841030e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bece48b02f684ddaa1e879adb7473594": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3606c4a79484900b1908e5adc8e03e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c884a89a2e648cda64bdbbd9a69379c",
            "placeholder": "​",
            "style": "IPY_MODEL_59856358c1954fbc9eae3b77b63e82fc",
            "value": " 8000/8000 [00:29&lt;00:00, 201.09it/s]"
          }
        },
        "d4efe5163fb346e7ac692657aee81c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd5ff417c64471b89a92e2507b5862e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4efe5163fb346e7ac692657aee81c1f",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3941431284af4546a75d3fff846a1d2d",
            "value": 8000
          }
        },
        "f55456f66b2f4194bf09e5bb2d0aa056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ec97c36e27e4c4e9e363e5ec9c18d91",
              "IPY_MODEL_dfd5ff417c64471b89a92e2507b5862e",
              "IPY_MODEL_c3606c4a79484900b1908e5adc8e03e8"
            ],
            "layout": "IPY_MODEL_bece48b02f684ddaa1e879adb7473594"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}